{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a large domain in the field of statistics and machine learning. Generally, classification can be broken down into two areas: \n",
    "\n",
    "1. **Binary classification**, where we wish to group an outcome into one of two groups.\n",
    "\n",
    "2. **Multi-class classification**, where we wish to group an outcome into one of multiple (more than two) groups.\n",
    "\n",
    "In this post, the main focus will be on using a variety of classification algorithms across both of these domains, less emphasis will be placed on the theory behind them.\n",
    "\n",
    "We can use libraries in Python such as <a rel=\"nofollow\" target=\"_blank\" href=\"http://scikit-learn.org/stable/\">scikit-learn</a> for machine learning models, and <a rel=\"nofollow\" target=\"_blank\" href=\"https://pandas.pydata.org/\">Pandas</a> to import data as data frames. These can be installed and imported into Python as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "python3 -m pip install sklearn\n",
    "python3 -m pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary classification, we are interested in classifying data into one of two *binary* groups - these are usually represented as 0's and 1's in our data. \n",
    "\n",
    "We will look at data regarding coronary heart disease (chd) in South Africa. The goal is to use different variables such as *tobacco usage*, *family history*, *ldl cholestrol levels*, *alcohol usage*, *obesity* and more. A full description is available in the data section of the <a rel=\"nofollow\" target=\"_blank\" href=\"https://web.stanford.edu/~hastie/ElemStatLearn/\">Elements of Statistical Learning</a> website. A sample of the data is shown below.\n",
    "\n",
    "The code below reads the data into a pandas data frame, and then separates the data frame into a y vector of the response and an X matrix of explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd\n",
       "0  160    12.00  5.73      23.11        1     49    25.30    97.20   52    1\n",
       "1  144     0.01  4.41      28.61        0     55    28.87     2.06   63    1\n",
       "2  118     0.08  3.48      32.28        1     52    29.14     3.81   46    0\n",
       "3  170     7.50  6.41      38.03        1     51    31.99    24.26   58    1\n",
       "4  134    13.60  3.50      27.78        1     60    25.99    57.34   49    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/stevenhurwitt/Documents/Blog/Classification')\n",
    "heart = pd.read_csv('SAHeart.csv', sep=',',header=0)\n",
    "heart.head()\n",
    "\n",
    "y = heart.iloc[:,9]\n",
    "X = heart.iloc[:,:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"nofollow\" target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Logistic Regression </a> is a type of Generalized Linear Model (GLM) that uses logistic function to model a binary variable based on any kind of independent variables.\n",
    "\n",
    "To fit a binary logistic regression with *sklearn*, we use the <a rel=\"nofollow\" target=\"_blank\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.htmlLogisticRegression\">LogisticRegression module</a> with multi_class set to *'ovr'* and fit X and y. We can then use the *predict* class to predict probabilities of new data, as well as the *score* class to get the mean prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/stevenhurwitt/Documents/Blog/Classification')\n",
    "heart = pd.read_csv('SAHeart.csv', sep=',',header=0)\n",
    "heart.head()\n",
    "\n",
    "y = heart.iloc[:,9]\n",
    "X = heart.iloc[:,:9]\n",
    "\n",
    "LR =  LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X, y)\n",
    "LR.predict(X.iloc[460:,:])\n",
    "round(LR.score(X,y), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"nofollow\" target=\"_blank\" href=\"https://scikit-learn.org/stable/modules/svm.html\">Support Vector Machines (SVMs) </a> are a type of classification algorithm that are more flexible - they can do linear classification, but can use other nonlinear *basis functions*. The following example uses a linear classifier to fit a hyperplane that separates the data into two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/stevenhurwitt/Documents/Blog/Classification')\n",
    "heart = pd.read_csv('SAHeart.csv', sep=',',header=0)\n",
    "\n",
    "y = heart.iloc[:,9]\n",
    "X = heart.iloc[:,:9]\n",
    "\n",
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X, y)\n",
    "SVM.predict(X.iloc[460:,:])\n",
    "round(SVM.score(X,y), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"nofollow\" target=\"_blank\" href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">Random Forests </a> are an ensemble learning method that fit multiple <a rel=\"nofollow\" target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Decision_tree\">Decision Trees </a> on subsets of the data and average the results. We can again fit them using *sklearn*, and use them to predict outcomes, as well as get mean prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7338"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "RF.fit(X,y)\n",
    "RF.predict(X.iloc[460:,:])\n",
    "round(RF.score(X,y), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"nofollow\" target=\"_blank\" href=\"https://en.wikipedia.org/wiki/Neural_network\">Neural Networks </a> are a machine learning algorithm that involves fitting many *hidden layers* used to represent neurons that are connected with synaptic *activation functions*. These essentially use a very simplified model of the brain to model and predict data.\n",
    "\n",
    "We use *sklearn* for consistency in this post, however libraries such as <a rel=\"nofollow\" target=\"_blank\" href=\"https://www.tensorflow.org/ \"> Tensorflow </a> and <a rel=\"nofollow\" target=\"_blank\" href=\"https://keras.io/ \"> Keras </a> are more suited to fitting and customizing neural networks, of which there are a few varieties used for different purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6537"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "NN.fit(X, y)\n",
    "NN.predict(X.iloc[460:,:])\n",
    "round(NN.score(X,y), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While binary classification alone is incredibly useful, there are times when we would like to model and predict data that has more than two classes. Many of the same algorithms can be used with slight modifications.\n",
    "\n",
    "Additionally, it is common to split data into *training* and *test* sets. This means we use a certain portion of the data to fit the model (the training set), and save the remaining portion of it to evaluate to the predictive accuracy of the fitted model (the test set).\n",
    "\n",
    "To explore both multi-class classification, as well as training/test data, we will look at another dataset from <a rel=\"nofollow\" target=\"_blank\" href=\"https://web.stanford.edu/~hastie/ElemStatLearn/\">Elements of Statistical Learning</a>: data used to determine which one of eleven vowel sounds were spoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x.1</th>\n",
       "      <th>x.2</th>\n",
       "      <th>x.3</th>\n",
       "      <th>x.4</th>\n",
       "      <th>x.5</th>\n",
       "      <th>x.6</th>\n",
       "      <th>x.7</th>\n",
       "      <th>x.8</th>\n",
       "      <th>x.9</th>\n",
       "      <th>x.10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.639</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.670</td>\n",
       "      <td>1.779</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>1.627</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>0.529</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>-0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.327</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-0.694</td>\n",
       "      <td>1.365</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>1.933</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>0.510</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>-0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.120</td>\n",
       "      <td>0.894</td>\n",
       "      <td>-1.576</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.707</td>\n",
       "      <td>1.559</td>\n",
       "      <td>-0.579</td>\n",
       "      <td>0.676</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>-0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.287</td>\n",
       "      <td>1.809</td>\n",
       "      <td>-1.498</td>\n",
       "      <td>1.012</td>\n",
       "      <td>-1.053</td>\n",
       "      <td>1.060</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>-0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-2.598</td>\n",
       "      <td>1.938</td>\n",
       "      <td>-0.846</td>\n",
       "      <td>1.062</td>\n",
       "      <td>-1.633</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y    x.1    x.2    x.3    x.4    x.5    x.6    x.7    x.8    x.9   x.10\n",
       "0  1 -3.639  0.418 -0.670  1.779 -0.168  1.627 -0.388  0.529 -0.874 -0.814\n",
       "1  2 -3.327  0.496 -0.694  1.365 -0.265  1.933 -0.363  0.510 -0.621 -0.488\n",
       "2  3 -2.120  0.894 -1.576  0.147 -0.707  1.559 -0.579  0.676 -0.809 -0.049\n",
       "3  4 -2.287  1.809 -1.498  1.012 -1.053  1.060 -0.567  0.235 -0.091 -0.795\n",
       "4  5 -2.598  1.938 -0.846  1.062 -1.633  0.764  0.394 -0.150  0.277 -0.396"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vowel_train = pd.read_csv('vowel.train.csv', sep=',',header=0)\n",
    "vowel_test = pd.read_csv('vowel.test.csv', sep=',',header=0)\n",
    "\n",
    "vowel_train.head()\n",
    "\n",
    "y_tr = vowel_train.iloc[:,0]\n",
    "X_tr = vowel_train.iloc[:,1:]\n",
    "\n",
    "y_test = vowel_test.iloc[:,0]\n",
    "X_test = vowel_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now fit models and test them as is normally done in statistics/machine learning: by training them on the training set and evaluating them on the test set.\n",
    "\n",
    "Additionally, since this is multi-class classification, some arguments will have to be changed within each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5455"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "vowel_train = pd.read_csv('vowel.train.csv', sep=',',header=0)\n",
    "vowel_test = pd.read_csv('vowel.test.csv', sep=',',header=0)\n",
    "\n",
    "y_tr = vowel_train.iloc[:,0]\n",
    "X_tr = vowel_train.iloc[:,1:]\n",
    "\n",
    "y_test = vowel_test.iloc[:,0]\n",
    "X_test = vowel_test.iloc[:,1:]\n",
    "\n",
    "LR =  LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_tr, y_tr)\n",
    "LR.predict(X_test)\n",
    "round(LR.score(X_test,y_test), 4)\n",
    "\n",
    "SVM = svm.SVC(decision_function_shape=\"ovo\").fit(X_tr, y_tr)\n",
    "SVM.predict(X_test)\n",
    "round(SVM.score(X_test, y_test), 4)\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0).fit(X_tr, y_tr)\n",
    "RF.predict(X_test)\n",
    "round(RF.score(X_test, y_test), 4)\n",
    "\n",
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(150, 10), random_state=1).fit(X_tr, y_tr)\n",
    "NN.predict(X_test)\n",
    "round(NN.score(X_test, y_test), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the implementations of these models were rather naive (in practice there are a variety of parameters that can and should be varied for each model), we can still compare the predictive accuracy across the models. This will tell us which one is the most accurate for this specific training and test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table {\n",
    "    font-family: arial, sans-serif;\n",
    "    border-collapse: collapse;\n",
    "    width: 100%;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "    border: 1px solid #dddddd;\n",
    "    text-align: left;\n",
    "    padding: 8px;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "    background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Model</th>\n",
    "    <th>Predictive Accuracy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Logistic Regression</td>\n",
    "    <td>46.1%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Support Vector Machine</td>\n",
    "    <td>64.07%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Random Forest</td>\n",
    "    <td>57.58%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Neural Network</td>\n",
    "    <td>54.55%</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that for the vowel data, an SVM using the default radial basis function was the most accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize this post, we began by exploring the simplest form of classification: binary. This helped us to model data where our response could take one of two states. We then moved further into multi-class classification, when the response variable can take any number of states. \n",
    "\n",
    "We also saw how to fit and evaluate models with training and test sets. Furthermore, we could explore additional ways to refine model fitting among various algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
