{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported modules.\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "import dateutil\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import socket\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import urllib\n",
    "from retrying import retry\n",
    "import pprint\n",
    "\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient import discovery\n",
    "from oauth2client import GOOGLE_TOKEN_URI\n",
    "from oauth2client.client import GoogleCredentials, OAuth2Credentials\n",
    "import google.oauth2.credentials\n",
    "import google_auth_oauthlib.flow\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "#from auth import DEFAULT_API_ROOT\n",
    "from energyworx_public import domain, rule\n",
    "from energyworx_public.base import EnergyworxDomain, StructuredProperty, Property, EnumProperty, DateTimeProperty, MappingStructuredProperty, MappingProperty, MappingEnumProperty\n",
    "from energyworx_public.enums import MappedFieldType, TransformationMapFunctionType, TagType, UnitType, VirtualDatasourceAggregationType, DatasourceType, DatapointType, TimeslicePeriodType\n",
    "from energyworx_client import client\n",
    "#from tags import parse_tags\n",
    "#from timeseries import parse_result_df, parse_nested_structure_result_df\n",
    "\n",
    "logger = logging.getLogger()\n",
    "pp = pprint.PrettyPrinter(1)\n",
    "print('imported modules.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Oauth Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working in /media/steven/big_boi/la-tools-test/ewx_client.\n"
     ]
    }
   ],
   "source": [
    "base = os.getcwd()\n",
    "print('working in {}.'.format(base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('client_secret_apps.googleusercontent.com.json', 'r') as f:\n",
    "    secret = json.load(f)\n",
    "    secret = secret['web']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### client secret json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': '71887862485-2e752er8kmsjns39idcb8i0819biji4q.apps.googleusercontent.com',\n",
       " 'project_id': 'ewx-api-access',\n",
       " 'auth_uri': 'https://accounts.google.com/o/oauth2/auth',\n",
       " 'token_uri': 'https://oauth2.googleapis.com/token',\n",
       " 'auth_provider_x509_cert_url': 'https://www.googleapis.com/oauth2/v1/certs',\n",
       " 'client_secret': 'Mn6oFIAq6vyrv39EjMso0kVo',\n",
       " 'redirect_uris': ['https://la-tools-engie.southcentralus.cloudapp.azure.com/hub/oauth_callback'],\n",
       " 'javascript_origins': ['http://52.228.24.147',\n",
       "  'https://la-tools-engie.southcentralus.cloudapp.azure.com']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Oauth2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returned status code: 200.\n",
      "https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=71887862485-2e752er8kmsjns39idcb8i0819biji4q.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fla-tools-engie.southcentralus.cloudapp.azure.com%2Fhub%2Foauth_callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly&state=J46EEnovdNbCkWyPEiP8Vx7OCxaTja&access_type=offline&include_granted_scopes=true\n"
     ]
    }
   ],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "\n",
    "flow = InstalledAppFlow.from_client_secrets_file('client_secret_apps.googleusercontent.com.json', SCOPES)\n",
    "flow.redirect_uri = secret['redirect_uris'][0]\n",
    "authorization_url, state = flow.authorization_url(access_type='offline', include_granted_scopes='true')\n",
    "\n",
    "response = requests.get(authorization_url)\n",
    "print('returned status code: {}.'.format(response.status_code))\n",
    "print(authorization_url)\n",
    "#creds = flow.run_console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'creds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a84f66f438be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'creds' is not defined"
     ]
    }
   ],
   "source": [
    "creds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input response url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redirect_response = input('paste url here: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://la-tools-engie.southcentralus.cloudapp.azure.com/hub/oauth_callback?state=MayCeY37tbOQP307iwN4X200Ll6Fbx&code=4/vAHnaaUCDm5FGINhFV8ylKiSyFrS9-ll8w5wmBdk7a4HjkdtwfXRRCTIYZ5IZlth9M4FWzqROe0gNs30SqVBEzQ&scope=https://www.googleapis.com/auth/gmail.readonly%20openid&authuser=0&session_state=d3e1e8b66f31ef53a250698d8536fa289b5d8993..50e6&prompt=consent\n"
     ]
    }
   ],
   "source": [
    "print(redirect_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': '4/vAHnaaUCDm5FGINhFV8ylKiSyFrS9-ll8w5wmBdk7a4HjkdtwfXRRCTIYZ5IZlth9M4FWzqROe0gNs30SqVBEzQ',\n",
      " 'scope': 'https://www.googleapis.com/auth/gmail.readonly%20openid&authuser=0',\n",
      " 'session_state': 'd3e1e8b66f31ef53a250698d8536fa289b5d8993..50e6',\n",
      " 'state': 'MayCeY37tbOQP307iwN4X200Ll6Fbx'}\n"
     ]
    }
   ],
   "source": [
    "auth = {'state':'MayCeY37tbOQP307iwN4X200Ll6Fbx', 'code':'4/vAHnaaUCDm5FGINhFV8ylKiSyFrS9-ll8w5wmBdk7a4HjkdtwfXRRCTIYZ5IZlth9M4FWzqROe0gNs30SqVBEzQ',\n",
    "       'scope':'https://www.googleapis.com/auth/gmail.readonly%20openid&authuser=0','session_state': 'd3e1e8b66f31ef53a250698d8536fa289b5d8993..50e6'}\n",
    "pp.pprint(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = requests.post('https://oauth2.googleapis.com/token', params = auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\n  \"error\": \"unsupported_grant_type\",\\n  \"error_description\": \"Invalid grant_type: \"\\n}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic get request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.googleapis.com/oauth2/v1/userinfo', creds)\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EWX API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWX(object):\n",
    "\n",
    "    def __init__(self, namespace_id=None, api_root=None, credentials=None):\n",
    "        super(EWX, self).__init__()\n",
    "        if not namespace_id:\n",
    "            namespace_id = os.environ.get('EWX_NAMESPACE')\n",
    "            logger.warning(\"No namespace parameter could be found, so we are using the primary namespace of the user\")\n",
    "        if not api_root:\n",
    "            api_root = DEFAULT_API_ROOT\n",
    "        self.namespace_id = namespace_id\n",
    "        self.api_root = api_root\n",
    "        logger.info('Using namespace = %s and api_root = %s', namespace_id, api_root)\n",
    "        #self.client = ExternalService.get_client(api_root=api_root, credentials=credentials)\n",
    "\n",
    "        \n",
    "    def __update_namespace(self, request, asynch=False):\n",
    "        request.headers.update({'x-namespace': self.namespace_id})\n",
    "        if asynch:\n",
    "            request.headers.update({'x-async-request': asynch})\n",
    "        return request\n",
    "\n",
    "    def __execute_and_handle_response(self, request, asynch=False):\n",
    "        try:\n",
    "            updated_request = self.__update_namespace(request, asynch)\n",
    "        except Exception as ex:\n",
    "            logger.error('Namespace could not be updated: %s', ex, exc_info=True)\n",
    "            raise Exception('Namespace could not be updated: {}'.format(ex))\n",
    "        for count in range(2):\n",
    "            try:\n",
    "                return updated_request.execute(num_retries=3)\n",
    "            except socket.error as socket_error:\n",
    "                if socket_error.strerror == 'Connection reset by peer':\n",
    "                    logger.info('%s -> retry', socket_error.strerror)\n",
    "                    continue\n",
    "            except HttpError:\n",
    "                raise\n",
    "            except Exception as ex:\n",
    "                logger.error('Request failed: %s', ex, exc_info=True)\n",
    "                raise Exception('Request failed: {}'.format(ex))\n",
    "\n",
    "    def upload_file(self, filename, file_content=None, tags=None, adapter_id=None, streaming=False):\n",
    "        \"\"\"It is important to use the exact same way of uploading data when developing, so this function\n",
    "        uploads files using the EDC way. First we get the upload url to blobstore via the API (using the\n",
    "        EWX client) and then we upload to blobstore API. The prepare process is then triggered by GAE\n",
    "        when a market adapter id is given.\n",
    "\n",
    "        Args:\n",
    "            filename (str): The filename to use when uploading\n",
    "            file_content (str): The file contents to upload\n",
    "            tags (list[str]): Tags that needs to be assigned to the file to be uploaded so it can be found in the filemanager\n",
    "            adapter_id (str): The adapter id, if given, after the upload an ingest will be triggered with this market adapter id\n",
    "            streaming (bool): When set to true, it will use the streaming pipeline\n",
    "\n",
    "        Returns:\n",
    "            object\n",
    "        \"\"\"\n",
    "        def _retry_if_exception(exception):\n",
    "            \"\"\" Specify an exception you need. or just True\"\"\"\n",
    "            return isinstance(exception, RuntimeError)\n",
    "            \n",
    "        STOP_MAX_DELAY = 600000\n",
    "        WAIT_EXPONENTIAL_MAX = 10000\n",
    "        WAIT_EXPONENTIAL_MULTIPLIER = 1000\n",
    "        @retry(retry_on_exception=_retry_if_exception, wait_exponential_multiplier=WAIT_EXPONENTIAL_MULTIPLIER, wait_exponential_max=WAIT_EXPONENTIAL_MAX, stop_max_delay=STOP_MAX_DELAY)\n",
    "        def _do_upload(upload_url, files, data):\n",
    "            logging.info(\"Using upload_url: %s\", upload_url)\n",
    "            response = requests.post(upload_url, files={filename: file_content},\n",
    "                                     data=dict(adapter_id=adapter_id, streaming=streaming),\n",
    "                                     headers={'X-NAMESPACE': self.namespace_id, 'Accept': 'application/json,application/vnd.ewx.v2'})\n",
    "            if 200 <= response.status_code < 300:\n",
    "                logging.info('File %s successfully uploaded', filename)\n",
    "                return response\n",
    "            else:    \n",
    "                logging.error('File %s could not be uploaded. Error: %s %s', filename, response.status_code, response.reason)\n",
    "                raise RuntimeError('File {} could not be uploaded. Error: {} {}'.format(filename, response.status_code, response.reason))\n",
    "                \n",
    "        if not file_content:\n",
    "            raise RuntimeError(\"File content is required!\")\n",
    "        if tags is None:\n",
    "            tags = []\n",
    "        logger.info(\"Uploading %s to blobstore with size %s\", filename, len(file_content))\n",
    "        res = self.get_upload_url(tags=tags, market_adapter_id=adapter_id, use_streaming=streaming)\n",
    "        if not res:\n",
    "            raise RuntimeError(\"Did not get a valid response for upload url\")\n",
    "        upload_url = res.get('uploadUrl')\n",
    "        if not upload_url:\n",
    "            raise RuntimeError(\"Could not create an uploadUrl with filename %s, and adapter_id %s\", filename, adapter_id)\n",
    "        return _do_upload(upload_url, files={filename: file_content}, data=dict(adapter_id=adapter_id, streaming=streaming))\n",
    "\n",
    "    def download_file(self, blob_key):\n",
    "        request_url = self.api_root + '/files/get/' + blob_key\n",
    "        credentials = ExternalService._get_credentials(None)\n",
    "        import httplib2\n",
    "        http = httplib2.Http(disable_ssl_certificate_validation=True, timeout=60)\n",
    "        credentials.authorize(http)\n",
    "        response, content = http.request(request_url, method='GET', headers={\n",
    "            'X-NAMESPACE': self.namespace_id,\n",
    "            'Accept': 'application/json,application/vnd.ewx.v2',\n",
    "        })\n",
    "\n",
    "        if 200 <= response.status < 300:\n",
    "            return content\n",
    "        else:\n",
    "            raise RuntimeError('File download error: {} {}'.format(response.status, response.reason))\n",
    "            \n",
    "            \n",
    "    def get_datasource(self, id):\n",
    "        \"\"\" Gets a datasource by identifier.\n",
    "\n",
    "        Args:\n",
    "            id (str): A datasource identifier as a string.\n",
    "\n",
    "        Returns:\n",
    "            dict: A datasource dictionary.\n",
    "        \"\"\"\n",
    "        request = self.client.datasource().datasource().get(id=id)\n",
    "        return self.__execute_and_handle_response(request)\n",
    "\n",
    "      # Query\n",
    "    def execute_query(self, query, job_id=None, limit=10, page_token=None, raw_result=False, priority='interactive'):\n",
    "        \"\"\" Execute an EQL query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The query as a string.\n",
    "            job_id (str): if provided, it will try to fetch the result from this job id\n",
    "            limit (int):\n",
    "            page_token (str or None):\n",
    "            raw_result (bool): return raw JSON result from API or parse into dataframe\n",
    "\n",
    "        Returns:\n",
    "            str or dict or pd.DataFrame: Results of the query in a dataframe.\n",
    "        \"\"\"\n",
    "        job_complete = False\n",
    "        while not job_complete:\n",
    "            request = self.client.query().query().execute(query=query, jobId=job_id, limit=limit, pageToken=page_token, priority=priority)\n",
    "            result = self.__execute_and_handle_response(request)\n",
    "            job_complete = result['reference'].get('jobComplete', True)\n",
    "            job_id = result['reference'].get('jobId')\n",
    "            time.sleep(0.1)\n",
    "        if isinstance(result, str) or raw_result:\n",
    "            return result\n",
    "        try:\n",
    "            return parse_result_df(result=result)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            return parse_nested_structure_result_df(result=result)\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            return parse_tags(result=result)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    def search_files(self, filename=None, tags=None, read_only=None, created_date=None, user_id=None, market_adapter_id=None, limit=None, page_token=None):\n",
    "        request = self.client.storage().storage().files().search(filename=filename, tags=tags,\n",
    "                                                                 readOnly=read_only, createdDate=created_date,\n",
    "                                                                 userId=user_id, marketAdapterId=market_adapter_id,\n",
    "                                                                 limit=limit, pageToken=page_token)\n",
    "        return self.__execute_and_handle_response(request)\n",
    "\n",
    "    def ingest_files(self, market_adapter_id=None, use_streaming=False, file_locations=None):\n",
    "        request = self.client.storage().storage().files().ingest(body=dict(marketAdapterId=market_adapter_id, useStreaming=use_streaming,\n",
    "                                                                 fileLocations=file_locations))\n",
    "        return self.__execute_and_handle_response(request)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewx = EWX('na.engie.com', 'https://ewx-live.appspot.com/_ah/api/', creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
